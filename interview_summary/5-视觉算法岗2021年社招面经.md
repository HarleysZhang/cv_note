- [社招面经](#社招面经)
- [一，项目](#一项目)
- [二，深度学习、模型部署](#二深度学习模型部署)
  - [2.1，目标检测相关](#21目标检测相关)
  - [2.2，深度学习相关](#22深度学习相关)
  - [2.3，模型部署相关](#23模型部署相关)
  - [2.4，编程语言相关](#24编程语言相关)
- [三，数据结构与算法 coding](#三数据结构与算法-coding)

> 个人背景：硕士毕业1年，面试的岗位大部分是计算机视觉算法工程师，少部分算法优化、部署岗。然后这个面经是去年写的，今天突然看到了，就发出来防止丢失。
## 社招面经
总的来说，大部分公司的技术面试都分为这几个部分：项目描述和细节提问、深度学习+目标检测算法、数据结构和算法代码及编程语言相关。下面是我面试当中问到的一些问题。

## 一，项目

主要是描述项目背景、项目实现的功能及使用的方法和流程，面试官会针对他感兴趣的点问一些技术细节，基本上只要能把项目流利的描述出来就问题不大。

## 二，深度学习、模型部署

### 2.1，目标检测相关

1，两阶段检测网络（`Faster RCNN` 系列）和一阶段检测网络（`YOLO` 系列）有什么区别？以及为什么两阶段比一阶段精度高？

- 双阶段网络算法更精细，把任务分成了正负样本分类、`bbox` 初次回归以及类别分类和 `bbox` 二次回归。
- 而 `YOLO` 算法更简单粗暴，使用 `backbone` 对输入图像提取特征后，将特征图划分成 $S\times S$ 的网格，物体的中心坐标落在哪个网络内，该网格（`grid`）就负责预测目标的置信度、类别和 `bbox`；`YOLOv2-v5` 通过 $1 \times 1$ 卷积输出特定通道数的特征图来，特征图有 `N` 个通道，对应的每个 `grid` 都会有 `N` 个值，分别对应置信度、类别和 `bbox` 坐标。

> 个人感觉这种问题不好回答，也没有标准答案，可能会出现你答的点不是面试官想要的。

可参考 [你一定从未看过如此通俗易懂的YOLO系列(从v1到v5)模型解读 (上)](https://zhuanlan.zhihu.com/p/183261974) 和 [一文读懂Faster RCNN](https://zhuanlan.zhihu.com/p/31426458) 文章，理解典型的双阶段检测网络和单阶段检测网络。

2，说说你对 `Focal Loss` 的理解，为什么能解决分类问题中的类别不平衡问题？

作者认为一阶段检测网络的精度不高的原因主要在于：极度不平衡的正负样本比例，从而导致**梯度（`gradient`）被容易样本（`easy example`）的损失主导**。

作者通过 `Focal Loss` 公式让置信度高（即容易样本）的样本的损失衰减的更厉害，从而降低容易样本的 `Loss` 权重，从而让模型在后期尽量去学习那些 `hard` 的样本。

3，如何在模型训练的时候判断是否过拟合，及模型过拟合问题如何解决？

将训练数据划分为训练集和验证集，`80%` 用于训练集，`20%` 用于验证集（训练集和验证集一定不能相交）；训练的时候每隔一定 `Epoch` 比较验证集但指标和训练集是否一致，如果不一致，并且验证集指标变差了，即意味着过拟合。

- `数据增强`, 增加数据多样性;
- 正则化策略：如 Parameter Norm Penalties (参数范数惩罚), `L1, L2` 正则化;
- 模型融合, 比如 `Bagging` 和其他集成方法;
- 添加 `BN`（batch normalization）层或者 `dropout` 层（现在基本不用）;
- `Early Stopping` (提前终止训练)。

4，如何在模型训练的时候判断是否欠拟合，及模型欠拟合问题如何解决？

`underfitting` 欠拟合的表现就是模型不收敛，即训练过程中验证集的指标比较差，`Loss` 不收敛。欠拟合的原因有很多种，这里以神经网络拟合能力不足问题给出以下参考解决方法：

- 寻找最优的权重初始化方案：如 `He` 正态分布初始化 `he_normal`，深度学习框架都内置了很多权重初始化方法；
- 使用适当的激活函数：卷积层的输出使用的激活函数一般为 `ReLu`，循环神经网络中的循环层使用的激活函数一般为 `tanh`，或者 `ReLu`；
- 选择合适的优化器和学习速率：`SGD` 优化器速度慢但是会达到最优.

5，描述以下 `YOLOv3` 算法及 `YOLOv4、YOLOv5` 的改进点，及为什么 `CIoU Loss` 比 `IoU Loss` 效果好？

`YOLOv3` 相比前代主要的改进点如下：

1. `Backbone` 从 `DarkNet19` 升级为 `DarkNet53`。
2. 添加了类似 `FPN` 的多尺度检测网络，解决小目标检测精度低的问题。
3. 分类预测使用多标签进行类别分类，不再使用 `softmax` 函数。
4. 每个 `ground truth` 对象只分配一个边界框。

6，描述下 `RoI Pooling` 过程和作用，以及 `RoI Align` 的改进点。

参考这篇文章 [Understanding Region of Interest — (RoI Align and RoI Warp)](https://towardsdatascience.com/understanding-region-of-interest-part-2-roi-align-and-roi-warp-f795196fc193)

7，`YOLOv3` 的标签编码解码过程，以及正负样本采样策略。

和 `YOLOv2` 一样，`YOLOv3` 依然使用 `K-means` 聚类的方法来挑选 `anchor boxes` 作为边界框预测的先验框。每个边界框都会预测 $4$ 个偏移坐标 $(t_x,t_y,t_w,t_h)$。假设 $(c_x, c_y)$ 为 `grid` 的左上角坐标，$p_w$、$p_h$ 是先验框（`anchors`）的宽度与高度，那么网络预测值和边界框真实位置的关系如下所示：
> 假设某一层的 `feature map` 的大小为 $13 \times 13$， 那么 `grid cell` 就有 $13 \times 13$ 个，则第 $n$ 行第 $n$ 列的 `grid cell` 的坐标 $(x_x, c_y)$ 就是 $(n-1,n)$。

$$
b_x = \sigma(t_x) + c_x \\\\
b_y = \sigma(t_y) + c_y \\\\
b_w = p_{w}e^{t_w} \\\\
b_h = p_{h}e^{t_h} $$

![偏移量计算](https://img2022.cnblogs.com/blog/2989634/202211/2989634-20221109225838812-165294405.png)

**正负样本的确定**：

+ 正样本：与 `GT` 的 `IOU` 最大的框。
+ 负样本：与 `GT` 的 `IOU<0.5` 的框。
+ 忽略的样本：与 `GT` 的 `IOU>0.5` 但不是最大的框。
+ 使用 $t_x$ 和 $t_y$ （而不是 $b_x$ 和 $b_y$ ）来计算损失。

8，详细讲解下 `Faster RCNN` 和 `Mask RCNN` 算法过程。

参考以下两篇文章理解 `Faster RCNN` 和 `Mask RCNN` 模型:

- [二阶段目标检测网络-Faster RCNN论文解读](https://zhuanlan.zhihu.com/p/562942597)
- [二阶段目标检测网络-Mask RCNN网络理解](https://zhuanlan.zhihu.com/p/562958404)

9，最新的目标检测算法有哪些？

`YOLOv4-v5`、`Scaled YOLOv4` 和 `Anchor-free` 的算法：`CenterNet`。

10，手写 `Soft NMS` 和 `Focal Loss`。

### 2.2，深度学习相关

1，BN 的作用及 BN 工作流程，以及训练和推理的区别？

2，普通卷积层、分组卷积、深度可分离卷积的 FLOPs 计算公式。

3，普通卷积层、分组卷积、深度可分离卷积的 MAC 计算公式。

4，详细描述下你知道的轻量级网络：MobileNetV1、ShuffleNetv1-v2。

5，何谓正则化？

通过给模型的代价函数（损失函数）添加被称为正则化项（`regularizer`）的惩罚，这称为将模型（学习函数为 $f(x; θ)$）正则化。正则化是一种思想（策略），**给代价函数添加惩罚**只是其中一种方法。

6，`L2` 正则化（权重衰减）原理，为什么它能防止模型过拟合？系数 $\lambda $ 如何取值？

`L2` 正则化（权重衰减）是另外一种正则化技术，通过加入的正则项对参数数值进行衰减，得到更小的权值。**当 $\lambda$ 较大时，会使得一些权重几乎衰减到零，相当于去掉了这一项特征，类似于减少特征维度**。假设待正则的网络参数为 $w$，`L2` 正则化为各个元素平方和的 $1/2$ 次方，其形式为：

$$L2 = \frac{1}{2}\lambda ||w||^{2}_{2}$$

实际使用时，一般将正则项加入目标函数，通过整体目标函数的误差反向传播，从而实现正则化影响和指导模型训练的目的。

7，`L1` 正则化原理，系数 $\lambda $ 如何取值？

`L1` 范数: 为向量 `x` 各个元素绝对值之和。`L1` 正则化可以使权值参数稀疏，方便特征提取。

8，`Pytorch` 的 `conv2d` 函数的参数有哪些？以及模型输出大小计算公式，并解释为什么公式是这样。

9，`Pytorch` 的 `DataLoader` 原理。

10，普通卷积过程描述下。

### 2.3，模型部署相关

1，浮点数在计算机中的表示方式？

2，描述下你知道的模型量化知识。

3，知识蒸馏原理，及温度系数如何取值？

4，通用矩阵乘（`GEMM`）优化算法有哪些？

二维矩阵相乘的 `C++` 代码如下；

```cpp
vector<vector<int>> matrix_mul(vector<vector<int>> A, vector<vector<int>> B){
    /*二维矩阵相乘函数，时间复杂度 O(n^3)
    */
    // vector<vector<int>> A_T = matrix_transpose(A);
    assert((*A.begin()).size()==B.size()); //断言，第一个矩阵的列必须等于第二个矩阵的行
    int new_rows = A.size();
    int new_cols = (*B.begin()).size();
    int L = B.size();
    vector<vector<int>> C(new_rows, vector<int>(new_cols,0));

    for(int i=0; i<new_rows; i++){
        for(int j=0; j<new_cols;j++){
            for(int k=0; k<L; k++){
                C[i][j] += A[i][k]*B[k][j];
            }
            // C[i][j] = vector_mul(A[i], get_col(B, j));
        }
    }
    return C;
}
```

对这样的矩阵乘的算法优化可分为两类：

- 基于算法分析的方法：根据矩阵乘计算特性，从数学角度优化，典型的算法包括 `Strassen` 算法和 `Coppersmith–Winograd` 算法。
- 基于软件优化的方法：根据计算机存储系统的层次结构特性，选择性地调整计算顺序，主要有循环拆分向量化、内存重排等。

### 2.4，编程语言相关

1，虚函数原理及作用？

2，`C++` 构造函数和析构函数的初始化顺序。

3，智能指针描述下？

4，`static` 关键字作用？

5，`STL` 库的容器有哪些，讲下你最熟悉的一种及常用函数。

6，`vector` 和 数组的区别？`vector` 扩容在内存中是怎么操作的？

7，引用和指针的区别？

8，C++ 中定义 int a = 2,; int b = 2 和 Python 中定义 a = 2 b=3 有什么区别？

9，`OpenCV` 读取图像返回后的矩阵在内存中是怎么保存的？

10，内存对齐原理描述，为什么需要内存对齐？

11，散列表的实现原理？

12，虚拟地址和物理内存的关系？


## 三，数据结构与算法 coding

1，二分查找算法 + 可运行代码。

2，白板写链表反转。

3，包含 min 函数的栈 + 可运行代码（剑指 Offer 30. 包含min函数的栈）

4，[最长回文子串](https://leetcode-cn.com/problems/longest-palindromic-substring/) + 时间复杂度

5，TOP k 问题-最小的 K 个数 + 说下你知道哪几种解法，及各自时间复杂度

6，返回转置后的矩阵（逆时针）

7，冒泡排序及优化

8，求数组中比左边元素都大同时比右边元素都小的元素，返回这些元素的索引

9，手写快速排序

10，手写 `softmax` 算子 + 解释代码及衍生问题

12，[无重复字符的最长子串](https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/)

13，N 皇后问题

14，求最大的第 k 个数