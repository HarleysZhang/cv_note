## 交并比IOU
交并比（Intersection-over-Union，IoU），目标检测中使用的一个概念，是产生的候选框（candidate bound）与原标记框（ground truth bound）的交叠率，即它们的交集与并集的比值。最理想情况是完全重叠，即比值为1。
计算公式如下：
![IOU计算公式](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/IOU%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F.png)

代码实现如下：
```python
import numpy as np
def iou(bbox1, bbox2):
    """
    计算两个bbox(两框的交并比)的iou值
    :param bbox1: (x1,y1,x2,y2), type: ndarray or list
    :param bbox2: (x1,y1,x2,y2), type: ndarray or list
    :return: iou, type float
    """
    if type(bbox1) or type(bbox2) != 'ndarray':
        bbox1 = np.array(bbox1)
        bbox2 = np.array(bbox2)
    assert bbox1.size == 4 and bbox2.size == 4, "bounding box coordinate size must be 4"
    xx1 = np.max((bbox1[0], bbox2[0]))
    yy1 = np.max((bbox1[1], bbox1[1]))
    xx2 = np.min((bbox1[2], bbox2[2]))
    yy2 = np.min((bbox1[3], bbox2[3]))
    bwidth = xx2 - xx1
    bheight = yy2 - yy1
    area = bwidth * bheight # 求两个矩形框的交集
    union = (bbox1[2] - bbox1[0])*(bbox1[3] - bbox1[1]) + (bbox2[2] - bbox2[0])*(bbox2[3] - bbox2[1]) - area # 求两个矩形框的并集
    iou = area / union
    return iou
if __name__=='__main__':
    rect1 = (661, 27, 679, 47)
    # (top, left, bottom, right)
    rect2 = (662, 27, 682, 47)
    iou = iou(rect1, rect2)
    print(iou)
```
## 非极大值抑制算法NMS
### [NMS介绍](https://juejin.im/entry/5bdbc26151882516da0ddd25)
在目标检测中，常会利用非极大值抑制算法(NMS，non maximum suppression)对生成的大量候选框进行后处理，去除冗余的候选框，得到最佳检测框，以加快目标检测的效率。其本质思想是其思想是搜素局部最大值，抑制非极大值。非极大值抑制，在计算机视觉任务中得到了广泛的应用，例如边缘检测、人脸检测、目标检测（DPM，YOLO，SSD，Faster R-CNN）等。即如图 2所示实现效果，消除多余的候选框，找到最佳的bbox。`NMS过程`如下图所示：

![NMS过程](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/NMS%E8%BF%87%E7%A8%8B.png)

以上图为例，每个选出来的Bounding Box检测框（既BBox）用（x,y,h,w, confidence score，Pdog,Pcat）表示，confidence score表示background和foreground的置信度得分，取值范围[0,1]。Pdog,Pcat分布代表类别是狗和猫的概率。如果是100类的目标检测模型，BBox输出向量为5+100=105。
### [NMS算法](https://juejin.im/entry/5bdbc26151882516da0ddd25)
NMS主要就是通过迭代的形式，不断地以最大得分的框去与其他框做IoU操作，并过滤那些IoU较大的框。
其实现的思想主要是将各个框的置信度进行排序，然后选择其中置信度最高的框A，将其作为标准选择其他框，同时设置一个阈值，[当其他框B与A的重合程度超过阈值就将B舍弃掉](https://blog.csdn.net/williamyi96/article/details/77996167 )，然后在剩余的框中选择置信度最大的框，重复上述操作。算法过程如下：
1. 根据候选框类别分类概率排序：F>E>D>C>B>A，并标记最大概率的矩形框F作为标准框。
2. 分别判断A~E与F的重叠度IOU(两框的交并比)是否大于某个设定的阈值，假设B、D与F的重叠度超过阈值，那么就扔掉B、D；
3. 从剩下的矩形框A、C、E中，选择概率最大的E，标记为要保留下来的，然后判读E与A、C的重叠度，扔掉重叠度超过设定阈值的矩形框；
4. 对剩下的bbx，循环执行(2)和(3)直到所有的bbx均满足要求（即不能再移除bbx）

**nms的python代码如下**：
```Python
import numpy as np

def py_nms(dets, thresh):
    """Pure Python NMS baseline.注意，这里的计算都是在矩阵层面上计算的
    greedily select boxes with high confidence and overlap with current maximum <= thresh
    rule out overlap >= thresh
    :param dets: [[x1, y1, x2, y2 score],] # ndarray, shape(-1,5)
    :param thresh: retain overlap < thresh
    :return: indexes to keep
    """
    # x1、y1、x2、y2、以及score赋值
    x1 = dets[:, 0]
    y1 = dets[:, 1]
    x2 = dets[:, 2]
    y2 = dets[:, 3]

    # 计算每一个候选框的面积, 纯矩阵加和乘法运算,为何加1？
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    # order是将confidence降序排序后得到的矩阵索引
    order = np.argsort(dets[:, 4])[::-1]
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        # 计算当前概率最大矩形框与其他矩形框的相交框的坐标，会用到numpy的broadcast机制，得到的是向量
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])

        # 计算相交框的面积,注意矩形框不相交时w或h算出来会是负数，用0代替
        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        # 计算重叠度IOU：重叠面积/（面积1+面积2-重叠面积）
        iou = inter / (areas[i] + areas[order[1:]] - inter)
        # 找到重叠度不高于阈值的矩形框索引
        inds = np.where(iou < thresh)[0]
        # 将order序列更新，由于前面得到的矩形框索引要比矩形框在原order序列中的索引小1，所以要把这个1加回来
        order = order[inds + 1]
    return keep

# test
if __name__ == "__main__":
    dets = np.array([[30, 20, 230, 200, 1],
                     [50, 50, 260, 220, 0.9],
                     [210, 30, 420, 5, 0.8],
                     [430, 280, 460, 360, 0.7]])
    thresh = 0.35
    keep_dets = py_nms(dets, thresh)
    print(keep_dets)
    print(dets[keep_dets])
```
程序输出如下：
> [0, 2, 3]
[[ 30. 20. 230. 200. 1. ]
 [210. 30. 420. 5. 0.8]
 [430. 280. 460. 360. 0.7]]

## Soft NMS算法
Soft NMS算法是对NMS算法的改进，是发表在ICCV2017的文章中提出的。`NMS`算法存在一个问题是可能会把一些目标框给过滤掉，从而导致目标的`recall`指标比较低。原来的NMS可以描述如下：将IOU大于阈值的窗口的得分全部置为0，计算公式如下：

![硬NMS算法](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E7%A1%ACNMS%E7%AE%97%E6%B3%95.jpg)

文章的改进有两种形式，一种是`线性加权`的。设 si 为第 i 个 box 的 score, 则在应用 SoftNMS 时各个 box score 的计算公式如下：

![线性加权形式的soft NMS算法](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E7%BA%BF%E6%80%A7%E5%8A%A0%E6%9D%83%E5%BD%A2%E5%BC%8F%E7%9A%84%E8%BD%AFNMS.jpg)

另一种是`高斯加权`的，高斯惩罚系数(与上面的线性截断惩罚不同的是, 高斯惩罚会对其他所有的 box 作用)，计算公式图如下：

![高斯加权形式的soft NMS算法](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E9%AB%98%E6%96%AF%E5%8A%A0%E6%9D%83%E5%BD%A2%E5%BC%8F%E7%9A%84NMS.jpg)

注意，这两种形式，思想都是M为当前得分最高框，$b_{i}$为待处理框， $b_{i}$和M的IOU越大，bbox的得分$s_{i}$就下降的越厉害($N_{t}$为给定阈值)。更多细节可以参考原[论文](https://arxiv.org/pdf/1704.04503.pdf)
soft nms的python代码如下：
```Python
def soft_nms(dets, thresh, type='gaussian'):
    x1 = dets[:, 0]
    y1 = dets[:, 1]
    x2 = dets[:, 2]
    y2 = dets[:, 3]
    scores = dets[:, 4]

    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = scores.argsort()[::-1]
    scores = scores[order]

    keep = []
    while order.size > 0:
        i = order[0]
        dets[i, 4] = scores[0]
        keep.append(i)

        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])

        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        # 计算重叠度IOU：重叠面积/（面积1+面积2-重叠面积）
        ovr = inter / (areas[i] + areas[order[1:]] - inter)

        order = order[1:]
        scores = scores[1:]
        if type == 'linear':
            inds = np.where(ovr >= thresh)[0]
            scores[inds] *= (1 - ovr[inds])
        else:
            scores *= np.exp(- ovr ** 2 / thresh)
        inds = np.where(scores > 1e-3)[0]
        order = order[inds]
        scores = scores[inds]

        tmp = scores.argsort()[::-1]
        order = order[tmp]
        scores = scores[tmp]
    return keep
```
## 类别AP计算
目标检测领域常用的评估标准是：`mAP(mean average precision)`，计算mAP需要先计算`AP`，计算`AP`需涉及到`precision`和`recall`的计算，而这两者的计算又需设计`TP`、`FP`、`FN`的计算。
`AP`的计算一般先设计到`P-R`曲线（precision-recall curve）的绘制，P-R曲线下面与x轴围成的面积称为`average precison（AP）`。下图是一个二分类问题的P-R曲线：

![分类问题的PR曲线图](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E5%88%86%E7%B1%BBPR%E6%9B%B2%E7%BA%BF%E5%9B%BE.png)

### 近似计算AP(approximated average precision)
$$AP = \sum_{k=1}^{N}P(k)\Delta r(k)$$
+ 这个计算方式称为 approximated 形式的，而插值计算的方式里面这个是最精确的，每个样本点都参与了计算
+ 很显然位于一条竖直线上的点对计算AP没有贡献
+ 这里N为数据总量，k为每个样本点的索引， Δr(k)=r(k)−r(k−1)

### 插值计算(Interpolated average precision)
插值计算AP的公式的演变过程我不写了，详情可以参考这篇[文章](https://arleyzhang.github.io/articles/c521a01c/)，我这里的公式和图也是参考此文章的。`11点插值计算方式计算AP公式`如下：

![11点插值计算方式计算AP公式](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E6%8F%92%E5%80%BC%E8%AE%A1%E7%AE%97AP%E5%85%AC%E5%BC%8F.png)

+ 这是通常意义上的 11points_Interpolated 形式的 AP，选取固定的 {0,0.1,0.2,…,1.0} 11个阈值，这个在PASCAL2007中有使用
+ 这里因为参与计算的只有11个点，所以 K=11，称为11points_Interpolated，k为阈值索引
+ $P_{interp}(k)$ 取第 k 个阈值所对应的样本点之后的样本中的最大值，只不过这里的阈值被限定在了 {0,0.1,0.2,…,1.0} 范围内。


![插值计算方式计算AP的PR曲线图](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E6%8F%92%E5%80%BC%E8%AE%A1%E7%AE%97AP%E7%9A%84PR%E6%9B%B2%E7%BA%BF%E5%9B%BE.png)

从曲线上看，真实 `AP< approximated AP < Interpolated AP`，11-points Interpolated AP 可能大也可能小，当数据量很多的时候会接近于 Interpolated AP，与 Interpolated AP不同，前面的公式中计算AP时都是对PR曲线的面积估计，PASCAL的论文里给出的公式就更加简单粗暴了，直接计算11个阈值处的precision的平均值。如下：

![PASCAL论文给出的11点计算AP公式](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/11%E7%82%B9%E8%AE%A1%E7%AE%97AP%E5%85%AC%E5%BC%8F.png)

### AP计算代码实现
近似计算`AP`和绘制·PR`曲线代码如下：
```Python
import numpy as np
import matplotlib.pyplot as plt

class_names = ["car", "pedestrians", "bicycle"]

def draw_PR_curve(predict_scores, eval_labels, name, cls_idx=1):
    """calculate AP and draw PR curve, there 3 types
    Parameters:
    @all_scores: single test dataset predict scores array, (-1, 3)
    @all_labels: single test dataset predict label array, (-1, 3)
    """
    # print('sklearn Macro-F1-Score:', f1_score(predict_scores, eval_labels, average='macro'))
    global class_names
    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 10))
    # Rank the predicted scores from large to small, extract their corresponding index(index number), and generate an array
    idx = predict_scores[:, cls_idx].argsort()[::-1]
    eval_labels_descend = eval_labels[idx]
    pos_gt_num = np.sum(eval_labels == cls_idx) # number of all gt

    predict_results = np.ones_like(eval_labels)
    tp_arr = np.logical_and(predict_results == cls_idx, eval_labels_descend == cls_idx) # ndarray
    fp_arr = np.logical_and(predict_results == cls_idx, eval_labels_descend != cls_idx)

    tp_cum = np.cumsum(tp_arr).astype(float) # ndarray, Cumulative sum of array elements.
    fp_cum = np.cumsum(fp_arr).astype(float)

    precision_arr = tp_cum / (tp_cum + fp_cum) # ndarray
    recall_arr = tp_cum / pos_gt_num
    ap = 0.0
    prev_recall = 0
    for p, r in zip(precision_arr, recall_arr):
      ap += p * (r - prev_recall)
      # pdb.set_trace()
      prev_recall = r
    print("------%s, ap: %f-----" % (name, ap))

    fig_label = '[%s, %s] ap=%f' % (name, class_names[cls_idx], ap)
    ax.plot(recall_arr, precision_arr, label=fig_label)

    ax.legend(loc="lower left")
    ax.set_title("PR curve about class: %s" % (class_names[cls_idx]))
    ax.set(xticks=np.arange(0., 1, 0.05), yticks=np.arange(0., 1, 0.05))
    ax.set(xlabel="recall", ylabel="precision", xlim=[0, 1], ylim=[0, 1])

    fig.savefig("./pr-curve-%s.png" % class_names[cls_idx])
    plt.close(fig)
```
voc中计算ap的代码（用的是插值计算方法，代码出自[这里](https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/voc_eval.py)）如下：
```Python
def voc_ap(rec, prec, use_07_metric=False):
    """ ap = voc_ap(rec, prec, [use_07_metric])
    Compute VOC AP given precision and recall.
    If use_07_metric is true, uses the
    VOC 07 11 point method (default:False).
    """
    if use_07_metric:
        # 11 point metric
        ap = 0.
        for t in np.arange(0., 1.1, 0.1):
            if np.sum(rec >= t) == 0:
                p = 0
            else:
                p = np.max(prec[rec >= t])
            ap = ap + p / 11.
    else:
        # correct AP calculation
        # first append sentinel values at the end
        mrec = np.concatenate(([0.], rec, [1.]))
        mpre = np.concatenate(([0.], prec, [0.]))

        # compute the precision envelope
        for i in range(mpre.size - 1, 0, -1):
            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])

        # to calculate area under PR curve, look for points
        # where X axis (recall) changes value
        i = np.where(mrec[1:] != mrec[:-1])[0]

        # and sum (\Delta recall) * prec
        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])
    return ap
```
## FLOPs计算
+ MACC：multiply-accumulate，乘法累加。
+ FLOPS：Floating-point Operations Per Second，每秒所执行的浮点运算次数。
> 先解释一下FLOPs：floating point operations 指的是浮点运算次数，理解为计算量，可以用来衡量算法/模型的复杂度。此处区分一下FLOPS（全部大写），FLOPS指的是每秒运算的浮点数，理解为计算速度，衡量一个硬件的标准。我们要的是衡量模型的复杂度的指标，所以选择FLOPs。

### 卷积层FLOPs计算
+ $FLOPs=(2\*Ci\*k\*K-1)\*H\*W\*Co$（不考虑bias）
+ $FLOPs=(2\*Ci\*k\*K）\*H\*W\*Co$（考虑bias）

**Ci为输入特征图通道数，K为过滤器尺寸，H,W,Co为输出特征图的高，宽和通道数**。`卷积过程`如下图所示：

![卷积过程](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B%E5%9B%BE.png)

公式解释，参考[这里](https://zhuanlan.zhihu.com/p/70306015?utm_source=wechat_session&utm_medium=social&utm_oi=571954943427219456)，如下：
最后得到的Co张输出特征图，每张特征图上有H\*W个像素点，而这其中的每个像素点的值都是由过滤器与输入特征图卷积得到的，过滤器中Ci\*k\*K个点，每个点都要和输入特征图对应点作一次相乘操作（浮点操作数为ci\*k\*k），然后将这些过滤器和输入特征图对应点相乘所得的数相加起来（浮点操作数为ci\*k\*k-1，n个数相加，所需要的浮点操作数为n-1），得到一个值，对应于一张输出特征图中的一个像素，输出特征图有Co张，故有Co个过滤器参与卷积运算，所以卷积层的**$FLOPs=(2\*Ci\*k\*K-1）\*H\*W\*Co$**

(Ci为输入特征图通道数，K为过滤器尺寸，H,W,Co为输出特征图的高，宽和通道数)
## anchors
所谓anchors，实际上就是一组由generate_anchors.py生成的矩形。其中每行的4个值 `(x1,y1,x2,y2)` 表矩形左上和右下角点坐标。9个矩形共有3种形状，长宽比为大约为 `{1:1, 1:2, 2:1}` 三种, 实际上通过anchors就引入了检测中常用到的多尺度方法。generate_anchors.py的代码如下：
```Python
import numpy as np
import six
from six import __init__  # 兼容python2和python3模块


def generate_anchor_base(base_size=16, ratios=[0.5, 1, 2],
                         anchor_scales=[8, 16, 32]):
    """Generate anchor base windows by enumerating aspect ratio and scales.

    Generate anchors that are scaled and modified to the given aspect ratios.
    Area of a scaled anchor is preserved when modifying to the given aspect
    ratio.

    :obj:`R = len(ratios) * len(anchor_scales)` anchors are generated by this
    function.
    The :obj:`i * len(anchor_scales) + j` th anchor corresponds to an anchor
    generated by :obj:`ratios[i]` and :obj:`anchor_scales[j]`.

    For example, if the scale is :math:`8` and the ratio is :math:`0.25`,
    the width and the height of the base window will be stretched by :math:`8`.
    For modifying the anchor to the given aspect ratio,
    the height is halved and the width is doubled.

    Args:
        base_size (number): The width and the height of the reference window.
        ratios (list of floats): This is ratios of width to height of
            the anchors.
        anchor_scales (list of numbers): This is areas of anchors.
            Those areas will be the product of the square of an element in
            :obj:`anchor_scales` and the original area of the reference
            window.

    Returns:
        ~numpy.ndarray:
        An array of shape :math:`(R, 4)`.
        Each element is a set of coordinates of a bounding box.
        The second axis corresponds to
        :math:`(y_{min}, x_{min}, y_{max}, x_{max})` of a bounding box.

    """
    import numpy as np
    py = base_size / 2.
    px = base_size / 2.

    anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4),
                           dtype=np.float32)
    for i in six.moves.range(len(ratios)):
        for j in six.moves.range(len(anchor_scales)):
            h = base_size * anchor_scales[j] * np.sqrt(ratios[i])
            w = base_size * anchor_scales[j] * np.sqrt(1. / ratios[i])

            index = i * len(anchor_scales) + j
            anchor_base[index, 0] = py - h / 2.
            anchor_base[index, 1] = px - w / 2.
            anchor_base[index, 2] = py + h / 2.
            anchor_base[index, 3] = px + w / 2.
    return anchor_base


# test
if __name__ == "__main__":
    bbox_list = generate_anchor_base()
    print(bbox_list)
```
程序运行输出如下：
> [[ -37.254833  -82.50967    53.254833   98.50967 ]
 [ -82.50967  -173.01933    98.50967   189.01933 ]
 [-173.01933  -354.03867   189.01933   370.03867 ]
 [ -56.        -56.         72.         72.      ]
 [-120.       -120.        136.        136.      ]
 [-248.       -248.        264.        264.      ]
 [ -82.50967   -37.254833   98.50967    53.254833]
 [-173.01933   -82.50967   189.01933    98.50967 ]
 [-354.03867  -173.01933   370.03867   189.01933 ]]

## 目标检测度量标准汇总
![目标检测指标汇总](https://github.com/HarleysZhang/2019_algorithm_intern_information/blob/master/images/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%86%E6%B1%87%E6%80%BB.jpg)
## 参考资料
+ [目标检测评价标准-AP mAP](https://arleyzhang.github.io/articles/c521a01c/)
+ [目标检测的性能评价指标](https://zhuanlan.zhihu.com/p/70306015?utm_source=wechat_session&utm_medium=social&utm_oi=571954943427219456)
+ [Soft-NMS](https://hellozhaozheng.github.io/z_post/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-SoftNMS-ICCV2017/)
+ [Recent Advances in Deep Learning for Object Detection](https://arxiv.org/abs/1908.03673v1)
+ [A Simple and Fast Implementation of Faster R-CNN](https://github.com/chenyuntc/simple-faster-rcnn-pytorch)
